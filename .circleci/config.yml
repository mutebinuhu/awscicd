# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
commands:
   # Exercise - Rollback
   destroy_environment:
     steps:
       - run:
           name: Destroy environment
           # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
           # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
           when: on_fail
           command: aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7}
jobs:
  say-hello:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: cimg/base:stable
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say hello"
          command: "echo Hello, World!"
  say-nuhu:
      docker:
        - image: cimg/base:stable
      steps:
        - checkout
        - run:
            name: "Say Nuhu"
            command: "echo Nuhu"

# Invoke jobs via workflows 
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows


  create_infrastructure: 
      docker:
        - image: amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
                --template-file template.yml \
                --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} \
                --region us-east-1
        - run: return 1
        - destroy_environment
    
 
  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
# Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

  get_last_deployment_id:
    docker:
    - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 

  promote_to_production:
    # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
# Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"   

  clean_up_old_front_end:
    # Destroy the previous production version's S3 bucket and CloudFormation stack. 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive            
  configure_infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
            # You can get this ID in the section where you registered the SSH Key
            fingerprints: ["f6:29:0a:ce:42:4e:64:92:26:14:01:00:6e:88:d2:77"]
            

      - run:
          name: Install Ansible
          command: apk add --update ansible 

      - run:
          name: Run Playbook and Configure server
          command: ansible-playbook -i inventory.ini main.yml
       
 # Exercise: Smoke Testing
  

  #say-hello-workflow:
    #jobs:
      #- say-hello
      #- say-nuhu
    
  #create_infrastructure-workflow:
    #jobs:
   
     #- configure_infrastructure
     #- create_infrastructure
  workflows:
    my_workflow:
      jobs:
        - create_and_deploy_front_end
        - promote_to_production:
            requires: 
              - create_and_deploy_front_end
        - get_last_deployment_id
        - clean_up_old_front_end:
            requires:
              - get_last_deployment_id
              - promote_to_production
   
